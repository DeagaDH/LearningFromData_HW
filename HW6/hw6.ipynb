{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# QUESTION 1\n",
    "\n",
    "Since $H'$ is a subset of $H$, the deterministic noise should, in general, increase, as $H'$ has less hypotheses available than $H$. Therefore, the correct alternative is **alternative b.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# SETUP CODE FOR QUESTIONS 2 - 6\n",
    "\n",
    "Run this before running the code for any of the above questions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw6_func import *\n",
    "\n",
    "#Initialize a data set of x (inputs) and y (target values)\n",
    "x,y = read_hw6_datasets('in.dta')\n",
    "\n",
    "#Transform x inputs\n",
    "x_tilde = hw6_transform(x)\n",
    "\n",
    "#Now create a test dataset\n",
    "x_test,y_test = read_hw6_datasets('out.dta')\n",
    "\n",
    "#Transform x_test inputs\n",
    "x_test_tilde = hw6_transform(x_test)\n",
    "\n",
    "def questions2to6(k=None,error_in=True,error_out=True):\n",
    "    \"\"\"\n",
    "    Runs the required Linear Regression code for questions 2 through 6\n",
    "    Input is the k value to use lambda = 10**k in questions 3 and beyond.\n",
    "    If k is set to none, then lambda=0\n",
    "    error_in = True -> evaluate in-sample error\n",
    "    error_out = True -> evaluate out of sample error\n",
    "    \"\"\"\n",
    "\n",
    "    #Set lamb value\n",
    "    if not k:\n",
    "        lamb = 0\n",
    "    else:\n",
    "        lamb = 10**k\n",
    "\n",
    "    #Run linear regression\n",
    "    #Initialize a LinearRegression object with the x and y lists\n",
    "    linreg = LinearRegression(x_tilde,y)\n",
    "\n",
    "    #Calculate the linear regression\n",
    "    linreg.learn(lamb=lamb)\n",
    "\n",
    "    if error_in and not error_out:\n",
    "        #Test learning in sample\n",
    "        e_in = linreg.test_learning(x_tilde,y)\n",
    "        return e_in\n",
    "\n",
    "    elif error_out and not error_in:\n",
    "        #Test learning out of sample\n",
    "        e_out = linreg.test_learning(x_test_tilde,y_test)\n",
    "        return e_out\n",
    "\n",
    "    else:\n",
    "        #Test learning in sample\n",
    "        e_in = linreg.test_learning(x_tilde,y)\n",
    "\n",
    "        #Test learning out of sample\n",
    "        e_out = linreg.test_learning(x_test_tilde,y_test)\n",
    "        return (e_in,e_out)\n",
    "    "
   ]
  },
  {
   "source": [
    "# QUESTION 2 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ein  = 0.03\nEout = 0.08\n"
     ]
    }
   ],
   "source": [
    "#Run the Linear Regression code with k=None (leads to lambda = 0)\n",
    "e_in,e_out = questions2to6(k=None)\n",
    "\n",
    "# Print results\n",
    "print(f'Ein  = {round(e_in,2)}')\n",
    "print(f'Eout = {round(e_out,2)}')\n"
   ]
  },
  {
   "source": [
    "# QUESTION 2 (ANSWER)\n",
    "\n",
    "From the above code, we can see that the correct alternative is **alternative a.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 3 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ein  = 0.03\nEout = 0.08\n"
     ]
    }
   ],
   "source": [
    "#Run the Linear Regression code with k=-3\n",
    "e_in,e_out = questions2to6(k=-3)\n",
    "\n",
    "# Print results\n",
    "print(f'Ein  = {round(e_in,2)}')\n",
    "print(f'Eout = {round(e_out,2)}')"
   ]
  },
  {
   "source": [
    "# QUESTION 3 (ANSWER)\n",
    "\n",
    "From the above code, we can see that the correct alternative is **alternative d.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 4 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ein  = 0.4\nEout = 0.4\n"
     ]
    }
   ],
   "source": [
    "#Run the Linear Regression code with k=3\n",
    "e_in,e_out = questions2to6(k=3)\n",
    "\n",
    "# Print results\n",
    "print(f'Ein  = {round(e_in,1)}')\n",
    "print(f'Eout = {round(e_out,1)}')"
   ]
  },
  {
   "source": [
    "# QUESTION 4 (ANSWER)\n",
    "\n",
    "From the above code, we can see that the correct alternative is **alternative e.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 5 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum Eout  = 0.06\nCorresponding k = -1\n"
     ]
    }
   ],
   "source": [
    "#Initialize a list of the k values in the alternatives\n",
    "k_list = [2, 1, 0, -1, -2]\n",
    "\n",
    "#Initialize e_out as an empty list\n",
    "e_out = []\n",
    "\n",
    "# Run the linear regression for all k values\n",
    "for k in k_list:\n",
    "    e_out.append(questions2to6(k=k,error_in=False))\n",
    "\n",
    "#Find minimum error and corresponding k\n",
    "e_out_min = min(e_out)\n",
    "k_min = k_list[e_out.index(e_out_min)]\n",
    "\n",
    "# Print results\n",
    "print(f'Minimum Eout  = {round(e_out_min,2)}')\n",
    "print(f'Corresponding k = {k_min}')"
   ]
  },
  {
   "source": [
    "# QUESTION 5 (ANSWER)\n",
    "\n",
    "From the above code, we can see that the correct alternative is **alternative d.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 6 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum Eout  = 0.06\nCorresponding k = -1\n"
     ]
    }
   ],
   "source": [
    "# Brute force: check a wide spectrum of k values to find the minimum\n",
    "k_list = range(-20,20)\n",
    "\n",
    "#Initialize e_out as an empty list\n",
    "e_out = []\n",
    "\n",
    "# Run the linear regression for all k values\n",
    "for k in k_list:\n",
    "    e_out.append(questions2to6(k=k,error_in=False))\n",
    "\n",
    "#Find minimum error and corresponding k\n",
    "e_out_min = min(e_out)\n",
    "k_min = k_list[e_out.index(e_out_min)]\n",
    "\n",
    "# Print results\n",
    "print(f'Minimum Eout  = {round(e_out_min,2)}')\n",
    "print(f'Corresponding k = {k_min}')"
   ]
  },
  {
   "source": [
    "# QUESTION 6 (ANSWER)\n",
    "\n",
    "From the above code, we can see that the correct alternative is **alternative b.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 7\n",
    "\n",
    "Comparing the two given equations, we can immediately eliminate **alternatives b and d**, as these alternatives have $C = 1$, which will lead to the second equations having different coefficients when compared to the first one for $q \\geq Q_o$. We can also readily eliminate **alternative a**, as the union of the two sets would lead to repeat elements.\n",
    "\n",
    "Analysing alternative c, we have that:\n",
    "\n",
    "\\begin{align}\n",
    "H(10,0,3) = \\Big\\lbrace h | h(x) &= \\sum_q^2 w_q L_q(x) \\Big\\rbrace \\\\ \\\\\n",
    "H(10,0,4) = \\Big\\lbrace h | h(x) &= \\sum_q^3 w_q L_q(x) \\Big\\rbrace \\\\ \\\\\n",
    "H(10,0,3) \\cap H(10,0,4) = \\Big\\lbrace h | h(x) &= \\sum_q^2 w_q L_q(x) \\Big\\rbrace = H_2\n",
    "\\end{align}\n",
    "\n",
    "Therefore, **alternative c is correct!**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 8\n",
    "\n",
    "For forward propagation, we have 22 total steps. This is equivalent to 1 step per weight, and we have 22 total weights. Of these,  we have 18 weights connecting layers $l=0$ and $l=1$ ($(d_0 + 1) \\times (d_1 +1) = 18$) and 4 weights connecting layers $l=1$ and $l=2$ ($(d_1 +1) * d_2 = 4$; no artificial node appears in the output layer).\n",
    "\n",
    "For back propagation, there are only 3 steps. We only update $\\delta$ in the single hidden layer $l=1$ and there is no $\\delta$ associeated with the artificial node.\n",
    "\n",
    "Finally, for updating the weights, once again we take 22 total steps, one per each weight.\n",
    "\n",
    "Therefore, the total number of steps is $N = 22 + 3 + 22 = 47$. **The correct alternative is alternative d.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 9\n",
    "\n",
    "The total number of weights of the neural network of $L$ layers can be written, in more general form, as:\n",
    "\n",
    "\\begin{equation}\n",
    "N_W = \\sum_{l=0}^{L-2} n^{(l)} (n^{(l+1)}-1) + n^{(L-1)}n^{L}\n",
    "\\end{equation}\n",
    "\n",
    "Where $n^{(l)}$ is the number of nodes on layer $l$. For the present problem, this is subjected to the restrictions:\n",
    "\n",
    "\\begin{align}\n",
    "n^{(0)} &= 10 \\\\\n",
    "n^{(L)} &= 1 \\\\\n",
    "\\sum_{l=1}^{L-1} n^{(l)} &= 36 \\\\\n",
    "n^{(l)} &> 1 \\text{ for } l < L\n",
    "\\end{align}\n",
    "\n",
    "The minimum number of connections (weights) occurs if all hidden layers have just a two units unit, resulting in 18 total hidden layers. In this scenario, the first equation reduces to:\n",
    "\n",
    "\\begin{equation}\n",
    "N_W = \\sum_{l=0}^{18} n^{(l)} (n^{(l+1)}-1)  + n^{(L-1)}n^{L}\n",
    "\\end{equation}\n",
    "\n",
    "Subject to:\n",
    "\n",
    "\\begin{align}\n",
    "L = 20 \\\\\n",
    "n^{(0)} &= 10 \\\\\n",
    "n^{(20)} &= 1 \\\\\n",
    "n^{(l)} &= 2 \\text{ for } 1 < l < 19\n",
    "\\end{align}\n",
    "\n",
    "Therefore,\n",
    "\\begin{equation}\n",
    "N_W = \\sum_{l=0}^{18} n^{(l)} (n^{(l+1)}-1) + n^{(L-1)}n^{L} = (10 \\times 1) + 17(2 \\times 1) + (2 \\times 1)\n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 10\n",
    "\n",
    "Here, we use the same equation for the total number of nodes derived for Question 9 above, but instead we use only 1 or 2 hidden layers; using more introduces more artificial points with no incoming weights, which reduces the total number of weights. For 1 hidden layer, the total number of weights is:\n",
    "\n",
    "\\begin{equation}\n",
    "N_W = 10 (36 - 1) + (36 \\times 1) = 386\n",
    "\\end{equation}\n",
    "\n",
    "For 2 hidden layers, many possible options are available. The code snippet below explores all possible options for 2 hidden layers:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "510\n22\n14\n"
     ]
    }
   ],
   "source": [
    "def unit_sum(l0=10,l1=2,l2=34,l3=1):\n",
    "\n",
    "    return l0*(l1-1) + l1*(l2-1) + l2*l3\n",
    "\n",
    "#Number of units in first and last layers\n",
    "l0 = 10\n",
    "l3 = 1\n",
    "\n",
    "#Hidden layers\n",
    "hidden = 2\n",
    "\n",
    "# Explore all combinations with two hidden layers\n",
    "nodes = 36\n",
    "\n",
    "# Both layers need at least 2 nodes, leaving us with 32 leftover nodes\n",
    "leftover = 36 - 2*hidden\n",
    "\n",
    "# Start max unit at 0 and iterate\n",
    "max_unit = 0\n",
    "max_l1 = 0\n",
    "max_l2 = 0\n",
    "\n",
    "# Explore all combinations\n",
    "for i in range(leftover+1):\n",
    "    l1 = 2+i #First hidden layer will have this many units\n",
    "    l2 = 2+(leftover-i)\n",
    "\n",
    "    units = unit_sum(l0=l0,l1=l1,l2=l2,l3=l3)\n",
    "\n",
    "    if units > max_unit:\n",
    "        max_unit = units\n",
    "        max_l1 = l1\n",
    "        max_l2 = l2\n",
    "\n",
    "print(max_unit)\n",
    "print(max_l1)\n",
    "print(max_l2)"
   ]
  },
  {
   "source": [
    "Therefore, we find that the maximum number of weights possible is **N_W = 510, alternative e.**. This combination is possible with 22 units in one of the two hidden layers and 14 units in the other hidden layer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}