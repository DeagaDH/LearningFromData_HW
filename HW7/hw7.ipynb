{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# QUESTIONS 1 TO 4 (CODE)\n",
    "\n",
    "See hw7_func.py for the definition of the questions1to4 function used below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "QUESTION 1\nMinimum Eout  = 0.0\nCorresponding k = 6\n\nQUESTION 2\nMinimum Eout  = 0.07\nCorresponding k = 7\n\nQUESTION 3\nMinimum Eout  = 0.08\nCorresponding k = 6\n\nQUESTION 3\nMinimum Eout  = 0.19\nCorresponding k = 6\n\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "\n",
    "#Initialize a data set of x (inputs) and y (target values)\n",
    "x,y = read_hw6_datasets('in.dta')\n",
    "\n",
    "#Initialize the validation dataset ('out.dta')\n",
    "x_out,y_out = read_hw6_datasets('out.dta')\n",
    "\n",
    "#Initialize a list of the k values in the alternatives\n",
    "k_list = [3,4,5,6,7]\n",
    "\n",
    "#Separate the initialized dataset (see setup code!)\n",
    "x_train,y_train,x_test,y_test = split_dataset(x,y,25)  \n",
    "\n",
    "#Run solution for Question 1\n",
    "questions1to4(x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,k_list=k_list,q_number=1)\n",
    "\n",
    "#Run solution for Question 2\n",
    "questions1to4(x_train=x_train,y_train=y_train,x_test=x_out,y_test=y_out,k_list=k_list,q_number=2)\n",
    "\n",
    "#Run solution for Question 3\n",
    "questions1to4(x_train=x_test,y_train=y_test,x_test=x_train,y_test=y_train,k_list=k_list,q_number=3)\n",
    "\n",
    "#Run solution for Question 3\n",
    "questions1to4(x_train=x_test,y_train=y_test,x_test=x_out,y_test=y_out,k_list=k_list,q_number=3)\n"
   ]
  },
  {
   "source": [
    "# QUESTIONS 1 TO 5 (ANSWERS)\n",
    "\n",
    "Answers are all based in the code snippets above. Question 5 just requires analysing what was derived in the previous questions.\n",
    "\n",
    "## Question 1\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 2\n",
    "**Alternative e.**\n",
    "\n",
    "## Question 3\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 4\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 5\n",
    "The out-of-sample error for the models chosen in Questions 1 and 3 was evaluated in Questions 2 and 4 respectively. Looking at the values derived for Questions 2 and 4, we see that the correct alternative is **Alternative b.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 6 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Expected value of e1: 0.5004\nExpected value of e2: 0.5001\nExpected value of e:  0.3335\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Brute forcing with many iterations\n",
    "N = 1000000\n",
    "\n",
    "#Start at 0\n",
    "e1 = 0\n",
    "e2 = 0\n",
    "e = 0\n",
    "\n",
    "for i in range(N):\n",
    "    temp1 = random.random()\n",
    "    temp2 = random.random()\n",
    "    e1 += temp1\n",
    "    e2 += temp2\n",
    "    e += min(temp1,temp2)\n",
    "\n",
    "e1 /= N\n",
    "e2 /= N\n",
    "e /= N\n",
    "\n",
    "print(f'Expected value of e1: {round(e1,4)}')\n",
    "print(f'Expected value of e2: {round(e2,4)}')  \n",
    "print(f'Expected value of e:  {round(e,4)}')  "
   ]
  },
  {
   "source": [
    "# QUESTION 6 (ANSWER)\n",
    "\n",
    "From the above code snippet, the correct alternative is **alternative d.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 8 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment number 1...\n",
      "Running experiment number 50...\n",
      "Running experiment number 100...\n",
      "Running experiment number 150...\n",
      "Running experiment number 200...\n",
      "Running experiment number 250...\n",
      "Running experiment number 300...\n",
      "Running experiment number 350...\n",
      "Running experiment number 400...\n",
      "Running experiment number 450...\n",
      "Running experiment number 500...\n",
      "Running experiment number 550...\n",
      "Running experiment number 600...\n",
      "Running experiment number 650...\n",
      "Running experiment number 700...\n",
      "Running experiment number 750...\n",
      "Running experiment number 800...\n",
      "Running experiment number 850...\n",
      "Running experiment number 900...\n",
      "Running experiment number 950...\n",
      "Running experiment number 1000...\n",
      "\n",
      "Average E_out for Perceptron: 0.1037\n",
      "Average E_out for SVM: 0.0889\n",
      "Average number of support vectors: 3\n",
      "SVM fared better in 59% of runs\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "#Initialize the problem\n",
    "#Coordinate limits for x and y\n",
    "xlim=[-1,1]\n",
    "ylim=[-1,1]\n",
    "\n",
    "#Number of points from the data set\n",
    "N = 10\n",
    "N_test = 10*N #Test data set\n",
    "\n",
    "#How many experiments to run?\n",
    "N_exp=1000\n",
    "\n",
    "#Define maximum number of iterations per experiment\n",
    "max_iter=100\n",
    "\n",
    "#Define \"infinity\" to use as the C value for the SVM\n",
    "inf=10000000000000000000\n",
    "\n",
    "#Initialize errors and support vector counts to 0\n",
    "error_perceptron=0\n",
    "error_svm = 0\n",
    "n_support = 0 \n",
    "svm_count = 0 # Counts how many times svm has been better\n",
    "\n",
    "for exp in range(0,N_exp):\n",
    "\n",
    "    #Display current experiment in console, every 50 experiments\n",
    "    if (exp+1 == 1) or ((exp+1) % 50 ==0):\n",
    "        print(f'Running experiment number {exp+1}...')\n",
    "\n",
    "    #Target line\n",
    "    target_function = line(random=True,xlim=xlim,ylim=ylim).map   \n",
    "\n",
    "    #Initialize a data set of x (point coordinates) and y (target values)\n",
    "    #Keep trying until the data set has both +1 and -1 values\n",
    "    while True:\n",
    "        x,y = create_dataset(random_point,target_function,N)\n",
    "\n",
    "        if (1 in y) and (-1 in y):\n",
    "            break\n",
    "    \n",
    "    #Now create a test dataset\n",
    "    x_test,y_test = create_dataset(random_point,target_function,N_test)\n",
    "\n",
    "    ####################################################################\n",
    "    #####                    PERCEPTRON\n",
    "    ####################################################################\n",
    "    \n",
    "    #Initialize perceptron with the x and y lists\n",
    "    p = Perceptron(x,y)\n",
    "\n",
    "    #Apply the learning algorithm and store iteration count\n",
    "    iter_count = p.learn(max_iter=max_iter)\n",
    "\n",
    "    #Test learning\n",
    "    current_error_perceptron = p.test_learning(x_test,y_test)\n",
    "    error_perceptron += current_error_perceptron \n",
    "\n",
    "    ####################################################################\n",
    "    #####                       SVM\n",
    "    ####################################################################\n",
    "    #Instantiate SVC object\n",
    "    svm = SVC(C=inf,kernel='linear')\n",
    "\n",
    "    #Fit\n",
    "    svm.fit(x,y)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = svm.predict(x_test)\n",
    "\n",
    "    #Evaluate error\n",
    "    current_error_svm = zero_one_loss(y_test, y_pred)\n",
    "    error_svm += current_error_svm\n",
    "    n_support += svm.n_support_[0] + svm.n_support_[1]\n",
    "\n",
    "    ####################################################################\n",
    "    #####                      COMPARISON\n",
    "    ####################################################################\n",
    "\n",
    "    # Which model has the smallest error?\n",
    "    if (current_error_svm < current_error_perceptron):\n",
    "        svm_count += 1 #Add to count if SVM is better\n",
    "\n",
    "#Average errors\n",
    "error_perceptron /= N_exp\n",
    "error_svm /= N_exp\n",
    "n_support /= N_exp\n",
    "svm_count /= N_exp\n",
    "\n",
    "#Print results\n",
    "print()\n",
    "print(f'Average E_out for Perceptron: {round(error_perceptron,4)}')\n",
    "print(f'Average E_out for SVM: {round(error_svm,4)}')\n",
    "print(f'Average number of support vectors: {int(round(n_support,0))}')\n",
    "print(f'SVM fared better in {int(round(svm_count*100,0))}% of runs')"
   ]
  },
  {
   "source": [
    "# QUESTION 8 (ANSWER)\n",
    "\n",
    "From the above code, the correct alternative is **alternative c.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTIONS 9 AND 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment number 1...\n",
      "Running experiment number 50...\n",
      "Running experiment number 100...\n",
      "Running experiment number 150...\n",
      "Running experiment number 200...\n",
      "Running experiment number 250...\n",
      "Running experiment number 300...\n",
      "Running experiment number 350...\n",
      "Running experiment number 400...\n",
      "Running experiment number 450...\n",
      "Running experiment number 500...\n",
      "Running experiment number 550...\n",
      "Running experiment number 600...\n",
      "Running experiment number 650...\n",
      "Running experiment number 700...\n",
      "Running experiment number 750...\n",
      "Running experiment number 800...\n",
      "Running experiment number 850...\n",
      "Running experiment number 900...\n",
      "Running experiment number 950...\n",
      "Running experiment number 1000...\n",
      "\n",
      "Average E_out for Perceptron: 0.0235\n",
      "Average E_out for SVM: 0.0106\n",
      "Average number of support vectors: 3\n",
      "SVM fared better in 70% of runs\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "#Initialize the problem\n",
    "#Coordinate limits for x and y\n",
    "xlim=[-1,1]\n",
    "ylim=[-1,1]\n",
    "\n",
    "#Number of points from the data set\n",
    "N = 100\n",
    "N_test = 10*N #Test data set\n",
    "\n",
    "#How many experiments to run?\n",
    "N_exp=1000\n",
    "\n",
    "#Define maximum number of iterations per experiment\n",
    "max_iter=100\n",
    "\n",
    "#Define \"infinity\" to use as the C value for the SVM\n",
    "inf=10000000000000000000\n",
    "\n",
    "#Initialize errors and support vector counts to 0\n",
    "error_perceptron=0\n",
    "error_svm = 0\n",
    "n_support = 0 \n",
    "svm_count = 0 # Counts how many times svm has been better\n",
    "\n",
    "for exp in range(0,N_exp):\n",
    "\n",
    "    #Display current experiment in console, every 50 experiments\n",
    "    if (exp+1 == 1) or ((exp+1) % 50 ==0):\n",
    "        print(f'Running experiment number {exp+1}...')\n",
    "\n",
    "    #Target line\n",
    "    target_function = line(random=True,xlim=xlim,ylim=ylim).map   \n",
    "\n",
    "    #Initialize a data set of x (point coordinates) and y (target values)\n",
    "    #Keep trying until the data set has both +1 and -1 values\n",
    "    while True:\n",
    "        x,y = create_dataset(random_point,target_function,N)\n",
    "\n",
    "        if (1 in y) and (-1 in y):\n",
    "            break\n",
    "    \n",
    "    #Now create a test dataset\n",
    "    x_test,y_test = create_dataset(random_point,target_function,N_test)\n",
    "\n",
    "    ####################################################################\n",
    "    #####                    PERCEPTRON\n",
    "    ####################################################################\n",
    "    \n",
    "    #Initialize perceptron with the x and y lists\n",
    "    p = Perceptron(x,y)\n",
    "\n",
    "    #Apply the learning algorithm and store iteration count\n",
    "    iter_count = p.learn(max_iter=max_iter)\n",
    "\n",
    "    #Test learning\n",
    "    current_error_perceptron = p.test_learning(x_test,y_test)\n",
    "    error_perceptron += current_error_perceptron \n",
    "\n",
    "    ####################################################################\n",
    "    #####                       SVM\n",
    "    ####################################################################\n",
    "    #Instantiate SVC object\n",
    "    svm = SVC(C=inf,kernel='linear')\n",
    "\n",
    "    #Fit\n",
    "    svm.fit(x,y)\n",
    "\n",
    "    #Predict\n",
    "    y_pred = svm.predict(x_test)\n",
    "\n",
    "    #Evaluate error\n",
    "    current_error_svm = zero_one_loss(y_test, y_pred)\n",
    "    error_svm += current_error_svm\n",
    "    n_support += svm.n_support_[0] + svm.n_support_[1]\n",
    "\n",
    "    ####################################################################\n",
    "    #####                      COMPARISON\n",
    "    ####################################################################\n",
    "\n",
    "    # Which model has the smallest error?\n",
    "    if (current_error_svm < current_error_perceptron):\n",
    "        svm_count += 1 #Add to count if SVM is better\n",
    "\n",
    "#Average errors\n",
    "error_perceptron /= N_exp\n",
    "error_svm /= N_exp\n",
    "n_support /= N_exp\n",
    "svm_count /= N_exp\n",
    "\n",
    "#Print results\n",
    "print()\n",
    "print(f'Average E_out for Perceptron: {round(error_perceptron,4)}')\n",
    "print(f'Average E_out for SVM: {round(error_svm,4)}')\n",
    "print(f'Average number of support vectors: {int(round(n_support,0))}')\n",
    "print(f'SVM fared better in {int(round(svm_count*100,0))}% of runs')"
   ]
  },
  {
   "source": [
    "# QUESTIONS 9 AND 10\n",
    "\n",
    "From the above code, the correct alternatives are:\n",
    "\n",
    "## QUESTION 9\n",
    "**Alternative d.**\n",
    "\n",
    "## QUESTION 10\n",
    "**Alternative b.**\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}