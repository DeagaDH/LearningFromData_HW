{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# QUESTIONS 1 TO 4 (CODE)\n",
    "\n",
    "See hw7_func.py for the definition of the questions1to4 function used below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "QUESTION 1\nMinimum Eout  = 0.0\nCorresponding k = 6\n\nQUESTION 2\nMinimum Eout  = 0.07\nCorresponding k = 7\n\nQUESTION 3\nMinimum Eout  = 0.08\nCorresponding k = 6\n\nQUESTION 3\nMinimum Eout  = 0.19\nCorresponding k = 6\n\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "\n",
    "#Initialize a data set of x (inputs) and y (target values)\n",
    "x,y = read_hw6_datasets('in.dta')\n",
    "\n",
    "#Initialize the validation dataset ('out.dta')\n",
    "x_out,y_out = read_hw6_datasets('out.dta')\n",
    "\n",
    "#Initialize a list of the k values in the alternatives\n",
    "k_list = [3,4,5,6,7]\n",
    "\n",
    "#Separate the initialized dataset (see setup code!)\n",
    "x_train,y_train,x_test,y_test = split_dataset(x,y,25)  \n",
    "\n",
    "#Run solution for Question 1\n",
    "questions1to4(x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test,k_list=k_list,q_number=1)\n",
    "\n",
    "#Run solution for Question 2\n",
    "questions1to4(x_train=x_train,y_train=y_train,x_test=x_out,y_test=y_out,k_list=k_list,q_number=2)\n",
    "\n",
    "#Run solution for Question 3\n",
    "questions1to4(x_train=x_test,y_train=y_test,x_test=x_train,y_test=y_train,k_list=k_list,q_number=3)\n",
    "\n",
    "#Run solution for Question 3\n",
    "questions1to4(x_train=x_test,y_train=y_test,x_test=x_out,y_test=y_out,k_list=k_list,q_number=3)\n"
   ]
  },
  {
   "source": [
    "# QUESTIONS 1 TO 5 (ANSWERS)\n",
    "\n",
    "Answers are all based in the code snippets above. Question 5 just requires analysing what was derived in the previous questions.\n",
    "\n",
    "## Question 1\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 2\n",
    "**Alternative e.**\n",
    "\n",
    "## Question 3\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 4\n",
    "**Alternative d.**\n",
    "\n",
    "## Question 5\n",
    "The out-of-sample error for the models chosen in Questions 1 and 3 was evaluated in Questions 2 and 4 respectively. Looking at the values derived for Questions 2 and 4, we see that the correct alternative is **Alternative b.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 6 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Expected value of e1: 0.4998\nExpected value of e2: 0.4997\nExpected value of e:  0.333\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Brute forcing with many iterations\n",
    "N = 1000000\n",
    "\n",
    "#Start at 0\n",
    "e1 = 0\n",
    "e2 = 0\n",
    "e = 0\n",
    "\n",
    "for i in range(N):\n",
    "    temp1 = random.random()\n",
    "    temp2 = random.random()\n",
    "    e1 += temp1\n",
    "    e2 += temp2\n",
    "    e += min(temp1,temp2)\n",
    "\n",
    "e1 /= N\n",
    "e2 /= N\n",
    "e /= N\n",
    "\n",
    "print(f'Expected value of e1: {round(e1,4)}')\n",
    "print(f'Expected value of e2: {round(e2,4)}')  \n",
    "print(f'Expected value of e:  {round(e,4)}')  "
   ]
  },
  {
   "source": [
    "# QUESTION 6 (ANSWER)\n",
    "\n",
    "From the above code snippet, the correct alternative is **alternative d.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTION 8 (CODE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment number 1...\n",
      "Running experiment number 50...\n",
      "Running experiment number 100...\n",
      "Running experiment number 150...\n",
      "Running experiment number 200...\n",
      "Running experiment number 250...\n",
      "Running experiment number 300...\n",
      "Running experiment number 350...\n",
      "Running experiment number 400...\n",
      "Running experiment number 450...\n",
      "Running experiment number 500...\n",
      "Running experiment number 550...\n",
      "Running experiment number 600...\n",
      "Running experiment number 650...\n",
      "Running experiment number 700...\n",
      "Running experiment number 750...\n",
      "Running experiment number 800...\n",
      "Running experiment number 850...\n",
      "Running experiment number 900...\n",
      "Running experiment number 950...\n",
      "Running experiment number 1000...\n",
      "\n",
      "Average E_out for Perceptron: 0.1035\n",
      "Average E_out for SVM: 0.0874\n",
      "Average number of support vectors: 3\n",
      "SVM fared better in 60% of runs\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "\n",
    "# See definition of this function in hw7_func.py.\n",
    "questions8and9(N=10,N_test_mult=10,N_exp=1000,xlim=[-1,1],ylim=[-1,1])"
   ]
  },
  {
   "source": [
    "# QUESTION 8 (ANSWER)\n",
    "\n",
    "From the above code, the correct alternative is **alternative c.**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# QUESTIONS 9 AND 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running experiment number 1...\n",
      "Running experiment number 50...\n",
      "Running experiment number 100...\n",
      "Running experiment number 150...\n",
      "Running experiment number 200...\n",
      "Running experiment number 250...\n",
      "Running experiment number 300...\n",
      "Running experiment number 350...\n",
      "Running experiment number 400...\n",
      "Running experiment number 450...\n",
      "Running experiment number 500...\n",
      "Running experiment number 550...\n",
      "Running experiment number 600...\n",
      "Running experiment number 650...\n",
      "Running experiment number 700...\n",
      "Running experiment number 750...\n",
      "Running experiment number 800...\n",
      "Running experiment number 850...\n",
      "Running experiment number 900...\n",
      "Running experiment number 950...\n",
      "Running experiment number 1000...\n",
      "\n",
      "Average E_out for Perceptron: 0.0229\n",
      "Average E_out for SVM: 0.0107\n",
      "Average number of support vectors: 3\n",
      "SVM fared better in 70% of runs\n"
     ]
    }
   ],
   "source": [
    "from hw7_func import *\n",
    "\n",
    "# See definition of this function in hw7_func.py.\n",
    "questions8and9(N=100,N_test_mult=10,N_exp=1000,xlim=[-1,1],ylim=[-1,1])"
   ]
  },
  {
   "source": [
    "# QUESTIONS 9 AND 10\n",
    "\n",
    "From the above code, the correct alternatives are:\n",
    "\n",
    "## QUESTION 9\n",
    "**Alternative d.**\n",
    "\n",
    "## QUESTION 10\n",
    "**Alternative b.**\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}